{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required module for preprocessing\n",
    "import os\n",
    "import skimage.io as io\n",
    "from skimage.transform import resize, rotate\n",
    "from skimage.util import random_noise, img_as_ubyte\n",
    "\n",
    "# assign directory\n",
    "directory = './dataset'\n",
    "output_directory = './dataset_preprocessed'\n",
    "skip_list = ['.DS_Store']\n",
    " \n",
    "is_debug = False\n",
    "skip_preprocessing = True\n",
    "fix_size = 64\n",
    "\n",
    "# save image with noise augmentation\n",
    "def noise_save(name, content):\n",
    "    io.imsave(name + '-1.png', img_as_ubyte(content))\n",
    "    image_noised_gaussian = random_noise(content, mode='gaussian', mean=0, var=0.01, clip=True)\n",
    "    io.imsave(name + '-2.png', img_as_ubyte(image_noised_gaussian))\n",
    "    image_noised_gaussian_2 = random_noise(content, mode='gaussian', mean=0, var=0.02, clip=True)\n",
    "    io.imsave(name + '-3.png', img_as_ubyte(image_noised_gaussian_2))\n",
    "    image_noised_s_p = random_noise(content, mode='s&p', salt_vs_pepper=0.5, clip=True)\n",
    "    io.imsave(name + '-4.png', img_as_ubyte(image_noised_s_p))\n",
    "    image_noised_s_p_2 = random_noise(content, mode='s&p', salt_vs_pepper=0.2, clip=True)\n",
    "    io.imsave(name + '-5.png', img_as_ubyte(image_noised_s_p_2))\n",
    "\n",
    "# save image with rotation augmentation\n",
    "def rotate_save(name, content):\n",
    "    noise_save(name + '-1', content)\n",
    "    content = rotate(content, 90)\n",
    "    noise_save(name + '-2', content)\n",
    "    content = rotate(content, 90)\n",
    "    noise_save(name + '-3', content)\n",
    "    content = rotate(content, 90)\n",
    "    noise_save(name + '-4', content)\n",
    "\n",
    "if not skip_preprocessing:\n",
    "    # iterate over files in that directory\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        f_out = os.path.join(output_directory, filename)\n",
    "        if not os.path.exists(f_out):\n",
    "            os.makedirs(f_out)\n",
    "        if os.path.isdir(f):\n",
    "            for imgname in os.listdir(f):\n",
    "                if (imgname in skip_list):\n",
    "                    continue\n",
    "                img = os.path.join(f, imgname)\n",
    "                img_raw = io.imread(img)\n",
    "                # Resize all data to fix size\n",
    "                image_resized = resize(img_raw, (fix_size, fix_size), anti_aliasing=True)\n",
    "                rotate_save(os.path.join(f_out, imgname[0: imgname.find('.')]), image_resized)\n",
    "                if is_debug:\n",
    "                    io.imshow(image_resized)\n",
    "                    break\n",
    "        if is_debug:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our data as standard input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1b', '1t', '1w', '2b', '2t', '2w', '3b', '3t', '3w', '4b', '4t', '4w', '5b', '5t', '5w', '6b', '6t', '6w', '7b', '7t', '7w', '8b', '8t', '8w', '9b', '9t', '9w', 'bai', 'bei', 'dong', 'fa', 'nan', 'xi', 'zhong']\n",
      "{'1b': 0, '1t': 1, '1w': 2, '2b': 3, '2t': 4, '2w': 5, '3b': 6, '3t': 7, '3w': 8, '4b': 9, '4t': 10, '4w': 11, '5b': 12, '5t': 13, '5w': 14, '6b': 15, '6t': 16, '6w': 17, '7b': 18, '7t': 19, '7w': 20, '8b': 21, '8t': 22, '8w': 23, '9b': 24, '9t': 25, '9w': 26, 'bai': 27, 'bei': 28, 'dong': 29, 'fa': 30, 'nan': 31, 'xi': 32, 'zhong': 33}\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import shutil\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "image_size = (64, 64)\n",
    "batch_size = 32\n",
    "\n",
    "path = '/tmp/dataset_cs5242'\n",
    "\n",
    "shutil.rmtree(path, ignore_errors=True)\n",
    "with zipfile.ZipFile(\"./dataset_preprocessed.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = torchvision.datasets.ImageFolder(root = path + \"/dataset_preprocessed\", transform=transform)\n",
    "\n",
    "print(dataset.classes)  # classes names\n",
    "print(dataset.class_to_idx) # index of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split our data to training set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11120 2780\n",
      "<class 'torchvision.datasets.folder.ImageFolder'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x10769e1c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_set_ratio = 0.2\n",
    "batch_size = 32\n",
    "import torch\n",
    "n = len(dataset)  # total number of examples\n",
    "n_test = int(validation_set_ratio * n)\n",
    "subsets = torch.utils.data.random_split(dataset, [n - n_test, n_test], generator=torch.Generator().manual_seed(42))\n",
    "train_set = subsets[0]\n",
    "test_set = subsets[1]\n",
    "print(train_set.__len__(), test_set.__len__()) # [train_set, validation_set]\n",
    "print(type(train_set.dataset))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_data_loader = DataLoader(train_set, batch_size, shuffle=True, num_workers=0)\n",
    "train_data_loader\n",
    "test_data_loader = DataLoader(test_set, batch_size, shuffle=True, num_workers=0)\n",
    "test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 64, 64, 3]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Sample for using the above data loaders\n",
    "for i, data in enumerate(train_data_loader, 0):\n",
    "    # iteration index, torch.Size([32, 64, 64, 3]) torch.Size([32])\n",
    "    print(i, data[0].permute(0, 2, 3, 1).shape, data[1].shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
